# Main Streamlit Application Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    tad.gitops.set/image: ".spec.template.spec.containers[0].image"
    tad.gitops.get/image: ".spec.template.spec.containers[0].image"
    tad.gitops.set/replicas: ".spec.replicas"
    tad.gitops.get/replicas: ".spec.replicas"
  labels:
    app.kubernetes.io/instance: ${{ values.name }}
    app.kubernetes.io/managed-by: kustomize
    app.kubernetes.io/name: ${{ values.name }}
    app.kubernetes.io/part-of: ${{ values.name }}
    app.kubernetes.io/component: streamlit-ui
  name: ${{ values.name }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: ${{ values.name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: ${{ values.name }}
        app.kubernetes.io/component: streamlit-ui
    spec:
      containers:
        - name: streamlit-app
          # Default bootstrap image - will be updated by Tekton pipeline via deployment-patch
          image: quay.io/redhat-ai-dev/agentic-sample:latest
          envFrom:
            - configMapRef:
                name: ${{ values.name }}-app-config
            - secretRef:
                name: ${{ values.appSecretName }}
                optional: false
          env:
            - name: LLAMA_STACK_URL
              value: "http://${{ values.name }}-llama-stack:8321"
            - name: LLAMA_STACK_SERVER_OPENAI
              value: "http://${{ values.name }}-llama-stack:8321/v1/openai/v1"
          ports:
            - containerPort: 8501
              name: http
              protocol: TCP
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "2Gi"
              cpu: "1000m"
          securityContext:
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              drop:
                - ALL
          readinessProbe:
            httpGet:
              path: /_stcore/health
              port: 8501
            initialDelaySeconds: 10
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /_stcore/health
              port: 8501
            initialDelaySeconds: 30
            periodSeconds: 30
          volumeMounts:
            - name: config-volume
              mountPath: /app/config
            - name: llama-data
              mountPath: /app/.llama
      volumes:
        - name: config-volume
          configMap:
            name: ${{ values.name }}-ingestion-config
        - name: llama-data
          emptyDir: {}

